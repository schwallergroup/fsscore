{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import gdown\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from intuitive_sc.utils.paths import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USPTO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load USPTO from Graph2SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_fns_dict = {\n",
    "    \"USPTO_50k\": [\n",
    "        (\"https://drive.google.com/uc?id=1pz-qkfeXzeD_drO9XqZVGmZDSn20CEwr\", \"src-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1ZmmCJ-9a0nHeQam300NG5i9GJ3k5lnUl\", \"tgt-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1NqLI3xpy30kH5fbVC0l8bMsMxLKgO-5n\", \"src-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=19My9evSNc6dlk9od5OrwkWauBpzL_Qgy\", \"tgt-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1l7jSqYfIr0sL5Ad6TUxsythqVFjFudIx\", \"src-test.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=17ozyajoqPFeVjfViI59-QpVid1M0zyKN\", \"tgt-test.txt\")\n",
    "    ],\n",
    "    \"USPTO_full\": [\n",
    "        (\"https://drive.google.com/uc?id=1PbHoIYbm7-69yPOvRA0CrcjojGxVCJCj\", \"src-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1RRveZmyXAxufTEix-WRjnfdSq81V9Ud9\", \"tgt-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1jOIA-20zFhQ-x9fco1H7Q10R6CfxYeZo\", \"src-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=19ZNyw7hLJaoyEPot5ntKBxz_o-_R14QP\", \"tgt-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1ErtNB29cpSld8o_gr84mKYs51eRat0H9\", \"src-test.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1kV9p1_KJm8EqK6OejSOcqRsO8DwOgjL_\", \"tgt-test.txt\")\n",
    "    ],\n",
    "    \"USPTO_480k\": [\n",
    "        (\"https://drive.google.com/uc?id=1RysNBvB2rsMP0Ap9XXi02XiiZkEXCrA8\", \"src-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1CxxcVqtmOmHE2nhmqPFA6bilavzpcIlb\", \"tgt-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1FFN1nz2yB4VwrpWaBuiBDzFzdX3ONBsy\", \"src-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1pYCjWkYvgp1ZQ78EKQBArOvt_2P1KnmI\", \"tgt-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=10t6pHj9yR8Tp3kDvG0KMHl7Bt_TUbQ8W\", \"src-test.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1FeGuiGuz0chVBRgePMu0pGJA4FVReA-b\", \"tgt-test.txt\")\n",
    "    ],\n",
    "    \"USPTO_STEREO\": [\n",
    "        (\"https://drive.google.com/uc?id=1r3_7WMEor7-CgN34Foj-ET-uFco0fURU\", \"src-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1HUBLDtqEQc6MQ-FZQqNhh2YBtdc63xdG\", \"tgt-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1WwCH8ASgBM1yOmZe0cJ46bj6kPSYYIRc\", \"src-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=19OsSpXxWJ-XWuDwfG04VTYzcKAJ28MTw\", \"tgt-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1FcbWZnyixhptaO6DIVjCjm_CeTomiCQJ\", \"src-test.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1rVWvbmoVC90jyGml_t-r3NhaoWVVSKLe\", \"tgt-test.txt\")\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'USPTO_50k'\n",
    "for url, fn in urls_fns_dict[dataset_name]:\n",
    "        os.makedirs(os.path.join(DATA_PATH, 'raw_uspto', dataset_name), exist_ok=True)\n",
    "        ofn = os.path.join(DATA_PATH, 'raw_uspto', dataset_name, fn)\n",
    "        if not os.path.exists(ofn):\n",
    "            gdown.download(url, ofn, quiet=False)\n",
    "            assert os.path.exists(ofn)\n",
    "        else:\n",
    "            print(f\"{ofn} exists, skip downloading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filepaths = glob.glob(os.path.join(DATA_PATH, 'raw_uspto', dataset_name, '*.txt'))\n",
    "uspto_data_prod = []\n",
    "uspto_data_react = []\n",
    "for filepath in raw_filepaths:\n",
    "    if 'train' in filepath:\n",
    "        split = 'train'\n",
    "    elif 'val' in filepath:\n",
    "        split = 'val'\n",
    "    elif 'test' in filepath:\n",
    "        split = 'test'\n",
    "    if 'src' in filepath:\n",
    "        moltype = 'product'\n",
    "        with open(filepath, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        # remove spaces between characters\n",
    "        lines = [''.join(line.strip().split()) for line in lines]\n",
    "        sub_df = pd.DataFrame(lines, columns=[moltype])\n",
    "        sub_df['split'] = split\n",
    "        uspto_data_prod.append(sub_df)\n",
    "    elif 'tgt' in filepath:\n",
    "        moltype = 'reactant'\n",
    "        with open(filepath, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [''.join(line.strip().split()) for line in lines]\n",
    "        sub_df = pd.DataFrame(lines, columns=[moltype])\n",
    "        sub_df['split'] = split\n",
    "        uspto_data_react.append(sub_df)\n",
    "    print(len(sub_df))\n",
    "uspto_data_prod = pd.concat(uspto_data_prod)\n",
    "uspto_data_react = pd.concat(uspto_data_react)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = []\n",
    "n = 0\n",
    "for smi in uspto_data_prod['product']:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        n +=1\n",
    "        print(smi)\n",
    "    mols.append(mol)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uspto_data_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uspto_data_prod), len(uspto_data_react)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uspto_prod_train = uspto_data_prod[uspto_data_prod['split'] == 'train']\n",
    "uspto_prod_val = uspto_data_prod[uspto_data_prod['split'] == 'val']\n",
    "uspto_prod_test = uspto_data_prod[uspto_data_prod['split'] == 'test']\n",
    "uspto_react_train = uspto_data_react[uspto_data_react['split'] == 'train']\n",
    "uspto_react_val = uspto_data_react[uspto_data_react['split'] == 'val']\n",
    "uspto_react_test = uspto_data_react[uspto_data_react['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create combined df with matching train, test, val split column and matching index\n",
    "uspto_train = pd.concat([uspto_react_train.drop(columns=['split']), uspto_prod_train], axis=1)\n",
    "uspto_val = pd.concat([uspto_react_val.drop(columns=['split']), uspto_prod_val], axis=1)\n",
    "uspto_test = pd.concat([uspto_react_test.drop(columns=['split']), uspto_prod_test], axis=1)\n",
    "# combine train, test, val\n",
    "uspto_data = pd.concat([uspto_train, uspto_val, uspto_test])\n",
    "uspto_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are instances where there are two reactants and sometimes the reactant is just CC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = []\n",
    "n_max = 1000\n",
    "for i, row in uspto_train.iterrows():\n",
    "    mol_prod = Chem.MolFromSmiles(row['product'])\n",
    "    mol_reac = Chem.MolFromSmiles(row['reactant'])\n",
    "    mols.append(mol_reac)\n",
    "    mols.append(mol_prod)\n",
    "    if i > n_max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.Draw.MolsToGridImage(mols[:20], molsPerRow=2, subImgSize=(300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all unfiltered reactions: ', len(uspto_data))    \n",
    "# remove rows with nan values\n",
    "uspto_data = uspto_data.dropna()\n",
    "print('after removing nan values: ', len(uspto_data))\n",
    "# remove rows with empty strings\n",
    "uspto_data = uspto_data[uspto_data['reactant'] != '']\n",
    "uspto_data = uspto_data[uspto_data['product'] != '']\n",
    "print('after removing empty strings: ', len(uspto_data))\n",
    "# remove rows with reactant and product that are the same\n",
    "uspto_data = uspto_data[uspto_data['reactant'] != uspto_data['product']]\n",
    "print('after removing reactant and product that are the same: ', len(uspto_data))\n",
    "# remove duplicates\n",
    "uspto_data = uspto_data.drop_duplicates(keep='first')\n",
    "print('after removing duplicates: ', len(uspto_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datapoints in two if there are two reactants (string has '.' in it)\n",
    "uspto_data_split = []\n",
    "for i, row in uspto_data.iterrows():\n",
    "    if '.' in row['reactant']:\n",
    "        reactants = row['reactant'].split('.')\n",
    "        for reactant in reactants:\n",
    "            sub_df = pd.DataFrame({'reactant': reactant, 'product': row['product']}, index=[i])\n",
    "            uspto_data_split.append(sub_df)\n",
    "    else:\n",
    "        sub_df = pd.DataFrame({'reactant': row['reactant'], 'product': row['product']}, index=[i])\n",
    "        uspto_data_split.append(sub_df)\n",
    "uspto_data_split = pd.concat(uspto_data_split)\n",
    "uspto_data_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canonicalize smiles\n",
    "uspto_data_split['reactant'] = uspto_data_split['reactant'].apply(lambda x: Chem.CanonSmiles(x))\n",
    "uspto_data_split['product'] = uspto_data_split['product'].apply(lambda x: Chem.CanonSmiles(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat filtering with canonicalized smiles before split!\n",
    "print('all unfiltered reactions: ', len(uspto_data_split))\n",
    "# remove rows with nan values\n",
    "uspto_data_split = uspto_data_split.dropna()\n",
    "print('after removing nan values: ', len(uspto_data_split))\n",
    "# remove rows with empty strings\n",
    "uspto_data_split = uspto_data_split[uspto_data_split['reactant'] != '']\n",
    "uspto_data_split = uspto_data_split[uspto_data_split['product'] != '']\n",
    "print('after removing empty strings: ', len(uspto_data_split))\n",
    "# remove rows with reactant and product that are the same\n",
    "uspto_data_split = uspto_data_split[uspto_data_split['reactant'] != uspto_data_split['product']]\n",
    "print('after removing reactant and product that are the same: ', len(uspto_data_split))\n",
    "# remove duplicates\n",
    "uspto_data_split = uspto_data_split.drop_duplicates()\n",
    "print('after removing duplicates: ', len(uspto_data_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "uspto_data.to_csv(os.path.join(DATA_PATH, 'raw_uspto', dataset_name, 'uspto_raw_combo.csv'))\n",
    "uspto_data_split.to_csv(os.path.join(DATA_PATH, 'raw_uspto', dataset_name, 'uspto_raw_split_combo.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "uspto_data = pd.read_csv(os.path.join(DATA_PATH, 'raw_uspto', dataset_name, 'uspto_raw_combo.csv'), index_col=0)\n",
    "uspto_data_split = pd.read_csv(os.path.join(DATA_PATH, 'raw_uspto', dataset_name, 'uspto_raw_split_combo.csv'), index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse graph from reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the graph using plotly\n",
    "def plot_graph(graph):\n",
    "    pos = nx.spring_layout(graph, k=0.5, iterations=50)\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    for edge in graph.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_x.append(x0)\n",
    "        edge_x.append(x1)\n",
    "        edge_x.append(None)\n",
    "        edge_y.append(y0)\n",
    "        edge_y.append(y1)\n",
    "        edge_y.append(None)\n",
    "\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x, y=edge_y,\n",
    "        line=dict(width=0.3, color='black'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines')\n",
    "\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    for node in graph.nodes():\n",
    "        x, y = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x, y=node_y,\n",
    "        mode='markers',\n",
    "        hoverinfo='text',\n",
    "        marker=dict(\n",
    "            showscale=True,\n",
    "            colorscale='YlGnBu',\n",
    "            reversescale=True,\n",
    "            color=[],\n",
    "            size=10,\n",
    "            colorbar=dict(\n",
    "                thickness=15,\n",
    "                title='Node Connections',\n",
    "                xanchor='left',\n",
    "                titleside='right'\n",
    "            ),\n",
    "            line_width=2))\n",
    "\n",
    "    node_adjacencies = []\n",
    "    node_text = []\n",
    "    for node, adjacencies in enumerate(G.adjacency()):\n",
    "        node_adjacencies.append(len(adjacencies[1]))\n",
    "        node_text.append(adjacencies[0])\n",
    "\n",
    "    node_trace.marker.color = node_adjacencies\n",
    "    node_trace.text = node_text\n",
    "\n",
    "    fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                    layout=go.Layout(\n",
    "                        title='USPTO Reaction Network',\n",
    "                        titlefont_size=16,\n",
    "                        showlegend=False,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(b=20, l=5, r=5, t=40),\n",
    "                        annotations=[dict(\n",
    "                            text=\"\",\n",
    "                            showarrow=False,\n",
    "                            xref=\"paper\", yref=\"paper\",\n",
    "                            x=0.005, y=-0.002)],\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of of (reactant, product) tuples\n",
    "reac_prod = list(zip(uspto_data_split['reactant'], uspto_data_split['product']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digraph = nx.DiGraph()\n",
    "digraph.add_edges_from(reac_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random rows from dataframe and extract reactant and product\n",
    "n_max = 1000\n",
    "subgraph_smiles = []\n",
    "for i, row in uspto_data_split.sample(n_max).iterrows():\n",
    "    subgraph_smiles.append(row['reactant'])\n",
    "    subgraph_smiles.append(row['product'])\n",
    "G = digraph.subgraph(subgraph_smiles)\n",
    "plot_graph(G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove molecules with less than 4 heavy atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(uspto_data_split, smilesCol='reactant', molCol='reactant_mol')\n",
    "PandasTools.AddMoleculeColumnToFrame(uspto_data_split, smilesCol='product', molCol='product_mol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows that have reactants or products with less than 4 heavy atoms\n",
    "uspto_data_split['reactant_natoms'] = uspto_data_split['reactant_mol'].apply(lambda x: x.GetNumHeavyAtoms())\n",
    "uspto_data_split['product_natoms'] = uspto_data_split['product_mol'].apply(lambda x: x.GetNumHeavyAtoms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_mols = uspto_data_split[(uspto_data_split['reactant_natoms'] < 4) | (uspto_data_split['product_natoms'] < 4)]\n",
    "len(small_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows that have reactants or products with less than 4 heavy atoms\n",
    "print(len(uspto_data_split))\n",
    "uspto_data_split_fil = uspto_data_split[(uspto_data_split['reactant_natoms'] >= 4) & (uspto_data_split['product_natoms'] >= 4)]\n",
    "print(len(uspto_data_split_fil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reac_prod_remove = list(zip(small_mols['reactant'], small_mols['product']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[node for node in digraph.nodes if digraph.degree(node) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove edges between reac_prod_remove\n",
    "digraph.remove_edges_from(reac_prod_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonely_nodes = [node for node in digraph.nodes if digraph.degree(node) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lonely nodes\n",
    "digraph.remove_nodes_from(lonely_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random rows from dataframe and extract reactant and product\n",
    "n_max = 1000\n",
    "subgraph_smiles = []\n",
    "for i, row in uspto_data_split_fil.sample(n_max).iterrows():\n",
    "    subgraph_smiles.append(row['reactant'])\n",
    "    subgraph_smiles.append(row['product'])\n",
    "G = digraph.subgraph(subgraph_smiles)\n",
    "plot_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uspto_data_split_fil.to_csv(os.path.join(DATA_PATH, 'raw_uspto', dataset_name, 'uspto_split_combo_fil_withloops.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uspto_data_split_fil = pd.read_csv(os.path.join(DATA_PATH, 'raw_uspto', dataset_name, 'uspto_split_combo_fil_withloops.csv'), index_col=0)\n",
    "reac_prod = list(zip(uspto_data_split_fil['reactant'], uspto_data_split_fil['product']))\n",
    "digraph = nx.DiGraph()\n",
    "digraph.add_edges_from(reac_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.find_cycle(digraph, orientation=\"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bicycle(digraph, df, self_loops=[]):\n",
    "    '''\n",
    "    Remove bicycle (two nodes connected to each other) from a directed graph recursively.\n",
    "    '''\n",
    "    try:\n",
    "        cycles = nx.find_cycle(digraph, orientation=\"original\")\n",
    "    except nx.NetworkXNoCycle:\n",
    "        return digraph, df, self_loops\n",
    "    for cycle in cycles:\n",
    "        # check if cycle is a self-loop (only connected to each other = remove)\n",
    "        if len(list(digraph.neighbors(cycle[0]))) == 1 and list(digraph.neighbors(cycle[0]))[0] == cycle[1]:\n",
    "            # remove edges\n",
    "            digraph.remove_edge(cycle[0], cycle[1])\n",
    "            digraph.remove_edge(cycle[1], cycle[0])\n",
    "            # remove nodes\n",
    "            digraph.remove_node(cycle[0])\n",
    "            digraph.remove_node(cycle[1])\n",
    "            df = df[~((df['reactant'] == cycle[0]) & (df['product'] == cycle[1]))]\n",
    "            df = df[~((df['reactant'] == cycle[1]) & (df['product'] == cycle[0]))]\n",
    "            self_loops.append((cycle[0], cycle[1]))\n",
    "            break\n",
    "    return remove_bicycle(digraph, df, self_loops)\n",
    "\n",
    "new_digraph, uspto_data_split_fil_lin, self_loops = remove_bicycle(digraph, uspto_data_split_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function above as for loop due to recursion limit\n",
    "def remove_bicycle(cycles, digraph, df, self_loops=[]):\n",
    "    '''\n",
    "    Remove bicycle (two nodes connected to each other) from a directed graph.\n",
    "    '''\n",
    "    for cycle in cycles:\n",
    "        # check if cycle is a self-loop (only connected to each other = remove)\n",
    "        if len(list(digraph.neighbors(cycle[0]))) == 1 and list(digraph.neighbors(cycle[0]))[0] == cycle[1]:\n",
    "            # remove edges\n",
    "            digraph.remove_edge(cycle[0], cycle[1])\n",
    "            digraph.remove_edge(cycle[1], cycle[0])\n",
    "            # remove nodes\n",
    "            digraph.remove_node(cycle[0])\n",
    "            digraph.remove_node(cycle[1])\n",
    "            df = df[~((df['reactant'] == cycle[0]) & (df['product'] == cycle[1]))]\n",
    "            df = df[~((df['reactant'] == cycle[1]) & (df['product'] == cycle[0]))]\n",
    "            self_loops.append((cycle[0], cycle[1]))\n",
    "            break\n",
    "    return digraph, df, self_loops\n",
    "\n",
    "# uspto_data_split_fil_lin = uspto_data_split_fil.copy()\n",
    "# while True:\n",
    "#     try:\n",
    "#         cycles = nx.find_cycle(digraph, orientation=\"original\")\n",
    "#         digraph, uspto_data_split_fil_lin, self_loops = remove_bicycle(cycles, digraph, uspto_data_split_fil_lin)\n",
    "#     except nx.NetworkXNoCycle:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uspto_data_split_fil_lin), len(uspto_data_split_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.find_cycle(digraph, orientation=\"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protection groups and hydroxy <-> aldehyde/ketone\n",
    "n = 1\n",
    "Chem.Draw.MolsToGridImage([Chem.MolFromSmiles(self_loops[n][0]),Chem.MolFromSmiles(self_loops[n][1]) ], molsPerRow=2, subImgSize=(300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.dag_longest_path_length(digraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_graph = nx.dag_longest_path(digraph)\n",
    "Chem.Draw.MolsToGridImage([Chem.MolFromSmiles(x) for x in longest_graph], subImgSize=(300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uspto_data_split_fil_lin.to_csv(os.path.join(DATA_PATH, 'raw_uspto', dataset_name, 'uspto_split_combo_fil.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final graph analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some stats on digraph\n",
    "print(nx.info(digraph))\n",
    "# 3 highest degree\n",
    "print(sorted(digraph.degree, key=lambda x: x[1], reverse=True)[:3])\n",
    "# get the longest path\n",
    "nx.dag_longest_path_length(digraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of nodes with degree 1\n",
    "len([node for node in digraph.nodes if digraph.degree(node) == 1]), len([node for node in digraph.nodes if digraph.out_degree(node) == 1]), len([node for node in digraph.nodes if digraph.in_degree(node) == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of heavy atoms\n",
    "# XXX far too small molecules!\n",
    "plt.hist(uspto_data_split_fil_lin['reactant_natoms'], bins=20, alpha=0.5, label='reactant');\n",
    "plt.hist(uspto_data_split_fil_lin['product_natoms'], bins=20, alpha=0.5, label='product');\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format for input\n",
    "* add label/target column\n",
    "* randomize position of reactants and products\n",
    "* columns\n",
    "    * smiles_i\n",
    "    * smiles_j\n",
    "    * target (what is more complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# seed\n",
    "random.seed(42)\n",
    "def format_rows(row):\n",
    "    # randomize reactants and products\n",
    "    if random.random() > 0.5:\n",
    "        return row['reactant'], row['product'], 1\n",
    "    else:\n",
    "        return row['product'], row['reactant'], 0\n",
    "    \n",
    "uspto_reorder = pd.DataFrame([format_rows(row) for _, row in uspto_data_split_fil_lin.iterrows()], columns=['smiles_i', 'smiles_j', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uspto_reorder.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uspto_reorder.to_csv(os.path.join(DATA_PATH, 'raw_uspto', dataset_name, 'uspto_input_trial.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intuitive-sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
